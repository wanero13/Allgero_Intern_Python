{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_zVfYjanWGWq"
   },
   "source": [
    "Twoim zadaniem jest wytrenowanie klasyfikatora binarnego na podzbiorze zbioru MNIST, w którym wyróżniamy klasy (cyfry 0 i 1 mają zostać wyłączone ze zbioru):\n",
    " - Liczby pierwsze (2,3,5,7)\n",
    " - Liczby złożone (4,6,8,9)\n",
    "\n",
    "Napisz wydajną implementację modelu **regresji logistycznej** trenowanego algorytmem ***SGD z momentum***. Cały proces trenowania musisz napisać samodzielnie, w języku Python, korzystając z biblioteki numpy. Na potrzeby zadania niedozwolone jest korzystanie z gotowych implementacji optimizerów i modeli oraz bibliotek do automatycznego różniczkowania funkcji (np. Tensorflow, pytorch, autograd). \n",
    "\n",
    "Dobierz hiperparametry tak, aby uzyskać jak najlepszy wynik na zbiorze walidacyjnym. \n",
    "Wyciągnij i zapisz wnioski z przeprowadzonych eksperymentów.\n",
    "\n",
    "Zbiór MNIST dostępny jest pod linkami: \n",
    "\n",
    "(zbiór treningowy):\n",
    " - http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
    " - http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
    "\n",
    "(zbiór walidacyjny):\n",
    " - http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
    " - http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Htj5iNRhWgz6"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import idx2numpy\n",
    "from math import exp\n",
    "indexl=[]\n",
    "indexv=[]\n",
    "\n",
    "class Model:\n",
    "  def __init__(self):\n",
    "    self.tl= idx2numpy.convert_from_file('data/train-labels.idx1-ubyte')\n",
    "    self.ti= idx2numpy.convert_from_file('data/train-images.idx3-ubyte')  \n",
    "    self.vl= idx2numpy.convert_from_file('data/t10k-labels.idx1-ubyte')  \n",
    "    self.vi= idx2numpy.convert_from_file('data/t10k-images.idx3-ubyte')\n",
    "    self.tl.setflags(write=1)\n",
    "    self.ti.setflags(write=1)\n",
    "    self.vl.setflags(write=1)\n",
    "    self.vi.setflags(write=1)\n",
    "\n",
    "  def fit(self) -> None:\n",
    "    for x in range(len(self.tl)):\n",
    "        if self.tl[x]==4 or self.tl[x]==6 or self.tl[x]==8 or self.tl[x]==9:\n",
    "            self.tl[x]=0\n",
    "        elif self.tl[x]==2 or self.tl[x]==3 or self.tl[x]==5 or self.tl[x]==7:\n",
    "            self.tl[x]=1\n",
    "        elif self.tl[x]==0 or self.tl[x]==1:\n",
    "            indexl.append(x)\n",
    "\n",
    "    for x in range(len(self.vl)):\n",
    "        if self.vl[x]==4 or self.vl[x]==6 or self.vl[x]==8 or self.vl[x]==9:\n",
    "            self.vl[x]=0\n",
    "        elif self.vl[x]==2 or self.vl[x]==3 or self.vl[x]==5 or self.vl[x]==7:\n",
    "            self.vl[x]=1\n",
    "        elif self.vl[x]==0 or self.vl[x]==1:\n",
    "            indexv.append(x)\n",
    "    self.tl=np.delete(self.tl,indexl)\n",
    "    self.ti=np.delete(self.ti,indexl,axis=0)\n",
    "    self.vl=np.delete(self.vl,indexv)\n",
    "    self.vi=np.delete(self.vi,indexv,axis=0)\n",
    "    self.vi=self.vi.astype(float)\n",
    "    for x in range(len(self.vl)):\n",
    "        for y in range(28):\n",
    "            for z in range(28):\n",
    "                nor=self.vi[x][y][z]/255.0\n",
    "                self.vi[x][y][z]=nor\n",
    "    self.ti=self.ti.astype(float)\n",
    "    for x in range(len(self.tl)):\n",
    "        for y in range(28):\n",
    "            for z in range(28):\n",
    "                nor=self.ti[x][y][z]/255.0\n",
    "                self.ti[x][y][z]=nor\n",
    "                \n",
    "    self.ti=self.ti.T\n",
    "    self.ti=self.ti.reshape(-1,self.ti.shape[-1])\n",
    "    self.ti=self.ti.T\n",
    "    self.vi=self.vi.T\n",
    "    self.vi=self.vi.reshape(-1,self.vi.shape[-1])\n",
    "    self.vi=self.vi.T\n",
    "\n",
    "  def calc(self, data, wsp):\n",
    "    pred = wsp[0]\n",
    "    for i in range(len(data)):\n",
    "        pred += wsp[i + 1] * data[i]\n",
    "    return 1.0 / (1.0 + exp(-pred))\n",
    "\n",
    "  def sgd(self, train, check , rate, n):\n",
    "    wsp = np.zeros(785)\n",
    "    for i in range(n):\n",
    "        for x in range(len(train)):\n",
    "            pred = self.calc(train[x], wsp)\n",
    "            var = check[x] - pred\n",
    "            wsp[0] = wsp[0] + rate * var * pred * (1.0 - pred)\n",
    "            for j in range(len(train[x])):\n",
    "                wsp[j + 1] = wsp[j+1] + rate * var * pred * (1.0 - pred) * train[x][j]\n",
    "        print(i)\n",
    "    return wsp\n",
    "\n",
    "  def predict(self, arr, check, wsp):\n",
    "        y_pred=np.zeros(len(check))\n",
    "        for x in range(len(arr)):\n",
    "            pred=round(self.calc(arr[x],wsp))\n",
    "            y_pred[x]=pred\n",
    "        print(self.evaluate(self.vl, y_pred))\n",
    "\n",
    "  @staticmethod\n",
    "  def evaluate(y_true: np.ndarray, y_pred: np.ndarray) -> float:\n",
    "    g = 0\n",
    "    for x in range(len(y_true)):\n",
    "        if y_true[x]==y_pred[x]:\n",
    "            g+=1\n",
    "    return g/len(y_true)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n"
     ]
    }
   ],
   "source": [
    "rate = 0.5\n",
    "n = 50\n",
    "wsp = model.sgd(model.ti[0:10000], model.tl, rate, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(wsp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9135066582117946\n"
     ]
    }
   ],
   "source": [
    "model.predict(model.vi,model.vl,wsp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Opis\n",
    "Niestety nie udało mi się zaimplementować SGD z momentum. To moja próba użycia regresji logistycznej trenowanej algorytmem SGD. Poniżej przedstawiam wyniki kilku testów. Sposób przedstawienia: n - liczba pętli, rate - ograniczenie korekty współcznnika, acc - wynik przetestowania modelu na zbiorze testowym, learning - tam gdzie został ograniczony zbiór uczący parametr learning pokazuje jego liczebność. Mała ilość pętli oraz ograniczenia elementów zbioru uczącego zostały spowodowane ograniczeniami sprzętowymi.\n",
    "\n",
    "* n: 1 rate: 0.5                  acc: 0.91224\n",
    "* n: 1 rate: 0.2                  acc: 0.91122\n",
    "* n: 1 rate: 1.0                  acc: 0.90641\n",
    "* n: 1 rate: 0.3                  acc: 0.90919\n",
    "* n: 5 rate: 0.5 learning: 10000  acc: 0.90717\n",
    "* n: 5 rate: 0.3 learning: 10000  acc: 0.91325\n",
    "* n: 20 rate: 0.5 learning: 10000 acc: 0.91325\n",
    "* n: 20 rate: 0.3 learning: 10000 acc: 0.91262\n",
    "* n: 50 rate: 0.5 learning: 10000 acc: 0.91351\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wnioski\n",
    "\n",
    "* Długi czas wykonania programu może być nie tylko spowodowany niskimi możliwościami obliczeniowymi sprzętu na którym przeprowadzono testy ale też błędnej/mało wydajnej implementacji algorytmu.\n",
    "\n",
    "* Warto zaznaczyć że dane na których były przeprowadzane testy zostały znormalizowane i szczególnie atrybuty ti i vi zostały zmienione z tablic 3-wymiarowych na 2-wymiarowe. Może to być nieoptymale i powodować spadek dokładności modelu.\n",
    "\n",
    "* Można zauwżyć że najwyższa dokładność jest dla n=50 co oznacza, że ilość iteracji pętli wyliczającej współczynniki tablicy w modelu zwiększa dokładność. Warto jednak zwrócić uwagę, że 5 iteracji daje słabsze wyniki niż tylko jedna iteracja, i że 20 iteracji ma lepszy wynik niż 1 i 5 iteracji ale mniej niż 50.\n",
    "\n",
    "* Występuje różnica pomiędzy ograniczeniem korekcji współczynników. Najleiej wypada 0.5, a najgorzej 1.\n",
    "\n",
    "* Należało by dodatkowo sprawdzić skuteczność innych parametrów rate przy większej liczbie iteracji niż tylko 0.5 i 0.3.\n",
    "\n",
    "* Przy większej liczbie iteracji rate=0.3 wypada podobnie do rate-0.5 dla 20 iteracji, ale lepiej przy 5 iteracjach.\n",
    "\n",
    "* Aby poprawić dokładność należało by zastanowić się nad sposobem przygotowania danych i być może go poprawić.\n",
    "\n",
    "* Warto zwrócić uwagę na fakt, że dla większej liczby iteracji niż 1 został użyty zmniejszony zbiór uczący. Należało by na lepszym sprzęcie przeprowadzić testy bez pomniejszonego zbioru uczącego."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Research_Engineer_Warszawa_i_Kraków",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
